{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil, glob, sys, math, cv2, re\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "from tqdm import tqdm\n",
    "# import normalizeStaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as cp\n",
    "from collections import OrderedDict\n",
    "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "from torch import Tensor\n",
    "from torch.jit.annotations import List\n",
    "from torchvision import models\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_record_folder = '/nfs/Shared/data/tcga/tumor'\n",
    "cohort_tumor_npy = sorted(os.listdir(tumor_record_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_images_dict = {i[:12]: [] for i in cohort_tumor_npy}    \n",
    "for npy in cohort_tumor_npy:\n",
    "    cohort_name = npy[:12]\n",
    "    image_names = np.load(os.path.join(tumor_record_folder, npy))\n",
    "    cohort_images_dict[cohort_name].extend(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數量500多，有些沒有images\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/coad_Mutation_Count.txt', delimiter=\"\\t\")\n",
    "cohort_count_dict = {row[1]: row[3] for index,row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 129\n"
     ]
    }
   ],
   "source": [
    "train_cohorts, valid_cohorts = train_test_split(\n",
    "    list(cohort_images_dict.keys()), test_size=0.33, random_state=42)\n",
    "print(len(train_cohorts), len(valid_cohorts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_labels(cohorts, cohort_images_dict, cohort_count_dict):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    no_expand_labels = []\n",
    "    for cohort in cohorts:\n",
    "        images = cohort_images_dict[cohort]\n",
    "        counts = [cohort_count_dict[cohort]]*len(images)\n",
    "        all_images.extend(images)\n",
    "        all_labels.extend(counts)\n",
    "        no_expand_labels.append(cohort_count_dict[cohort])\n",
    "    return np.array(all_images), np.array(all_labels), np.array(no_expand_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvt2percentile(counts, labels):\n",
    "    percentile = np.percentile(counts, [25,75])\n",
    "    print(percentile)\n",
    "    percentile_labels = np.zeros_like(labels)\n",
    "    \n",
    "    for idx, label in enumerate(labels):\n",
    "        _foo = (label < percentile)*1\n",
    "        if np.sum(_foo) == 0:\n",
    "            percentile_labels[idx] = 2\n",
    "        else:\n",
    "            for _temp, _i in enumerate(_foo):\n",
    "                if _i == 1:\n",
    "                    percentile_labels[idx] = _temp\n",
    "                    break\n",
    "#         print(label, percentile_labels[idx])\n",
    "    return percentile_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706943 706943 261 302523 302523 129\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, train_counts = get_images_labels(train_cohorts, cohort_images_dict, cohort_count_dict)\n",
    "valid_images, valid_labels, valid_counts = get_images_labels(valid_cohorts, cohort_images_dict, cohort_count_dict)\n",
    "\n",
    "print(len(train_images), len(train_labels), len(train_counts), len(valid_images), len(valid_labels), len(valid_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81. 168.]\n",
      "[ 88. 151.]\n"
     ]
    }
   ],
   "source": [
    "train_labels = cvt2percentile(train_counts, train_labels)\n",
    "valid_labels = cvt2percentile(valid_counts, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.Resize(height = 224, width = 224, always_apply=True),\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "# https://github.com/pytorch/vision/blob/master/torchvision/transforms/functional.py, to_tensor     \n",
    "def to0_1(x, **kwargs):\n",
    "    return x/255\n",
    "\n",
    "def get_preprocessing():\n",
    "    _transform = [\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "        albu.Lambda(image=to0_1, mask=to0_1),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \n",
    "    def __init__(self, image_array, label_array, augmentation=None, preprocessing=None):\n",
    "        self.image_array = image_array\n",
    "        self.label_array = label_array\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        fp = self.image_array[i]\n",
    "        \n",
    "        image = cv2.imread(fp)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         imgNorm= normalizeStaining.normalizeStaining(img = im_rgb)\n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "        \n",
    "        label = self.label_array[i]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "epoch = 60\n",
    "model_arch = 'resnet18'\n",
    "train_loss = 'ce'\n",
    "train_metric = 'fscore'\n",
    "use_sampler = True\n",
    "init_lr = 1e-4\n",
    "nclass = 3\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 10 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(in_features=512, out_features=nclass, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_loader:\n",
    "    image, label = i\n",
    "    model.cuda()\n",
    "    image = image.cuda()\n",
    "    with torch.no_grad():\n",
    "         pred = model(image)\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    augmentation=get_augmentation(),\n",
    "    preprocessing=get_preprocessing(),\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    valid_images,\n",
    "    valid_labels,\n",
    "    augmentation=get_augmentation(),\n",
    "    preprocessing=get_preprocessing(),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, pin_memory=True, num_workers=16)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, pin_memory=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = utils.metrics.CrossEntropy()\n",
    "metrics = [\n",
    "    utils.metrics.Fscore(),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "valid:   1%|▏         | 64/4727 [00:40<09:05,  8.54it/s, cross entropy - 1.627, fscore - 1.275]   "
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "\n",
    "for i in range(0, 40):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_time = time.strftime(\"%Y_%m_%d_%H_%M\", time.localtime())\n",
    "\n",
    "model_name = './weight/' + \"{}_MCnt-centile3-loss:{}_bs:{}\".format(\n",
    "    current_time, train_loss, bs)\n",
    "\n",
    "cur_metric = 0\n",
    "\n",
    "train_history = []\n",
    "valid_history = []\n",
    "for i in range(0, epoch):\n",
    "    print('\\nEpoch: {}, batch: {}'.format(i, bs))\n",
    "    \n",
    "    # lr_scheduler.step()\n",
    "    adjust_learning_rate(optimizer, i)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    \n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    train_history.append(train_logs)\n",
    "    valid_history.append(valid_logs)\n",
    "    \n",
    "    if cur_metric < valid_logs[metrics[0].__name__]:\n",
    "        cur_metric = valid_logs[metrics[0].__name__]\n",
    "        torch.save(model.state_dict(), model_name+\"_epoch{}_{}:{:.4f}\".format(i,train_metric, cur_metric)+\".h5\")\n",
    "        print('Model saved!', model_name+\"_epoch{}_{}:{:.4f}\".format(i,train_metric, cur_metric)+\".h5\")\n",
    "\n",
    "#     if cur_metric > valid_logs[metrics[0].__name__]:\n",
    "#         cur_metric = valid_logs[metrics[0].__name__]\n",
    "#         torch.save(model.state_dict(), model_name+\"_epoch{}_{}:{:.4f}\".format(i,train_metric, cur_metric)+\".h5\")\n",
    "#         print('Model saved!', model_name+\"_epoch{}_{}:{:.4f}\".format(i,train_metric, cur_metric)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
